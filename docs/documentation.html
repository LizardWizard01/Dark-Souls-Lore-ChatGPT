<!DOCTYPE html>
<html>
    <head>
        <title>Documentation</title>
        <link rel="stylesheet" type="text/css" href="style.css" />
    </head>
    <body>
        <nav>
            <ul>
                <li>
                    <a href="index.html">Home</a>
                </li>
                <li>
                    <a href="about.html">About</a>
                </li>
                <li>
                    <a href="documentation.html">Documentation</a>
                </li>
                <li>
                    <a href="visualization.html">Visualization</a>
                </li>
                <li>
                    <a href="problems.html">Problems</a>
                </li>
                <li>
                    <a href="examples.html">Examples</a>
                </li>
                <li>
                    <a href="https://github.com/LizardWizard01/Dark-Souls-Lore-ChatGPT">GitHub
                        Repo</a>
                </li>
            </ul>
        </nav>
        <div class="doc">
            <h1>From the beginning</h1>
            <br />
            <p>We started this project by wanting to compare the in-game lore of weapons, armor, and
                other items in the video game Dark Souls with results that could be generated from
                the openai chatbot, ChatGPT. </p>
            <p>Our goal was to simply run prompts through chatGPT and get a fictional set of items
                that are generated by the chat bot and would have the ability to function as actual
                in-game lore. With that in mind, we were planning on evaluating the similarities and
                differences between the existing set of items from the <a
                    href="https://docs.google.com/spreadsheets/d/1nU-PlT4giFSGspGPTtZmt8XS2cPw4pCuf__J0Izfqqw/edit?usp=sharing"
                    >google sheet we discovered</a> and our fictional set that would be generated. </p>
            <p>To start this process, we had to be able to scrape the information that we needed
                from the google sheet. We started looking at resources for Python that could allow
                us to do this, but soon realized there was a much simpler way to achieve this. We
                copied the columns we needed into a new excel sheet, and then exported it as a text
                file. This came with a few more bits of work, but ultimately it was what we wanted.
                The last steps to output only the item type, name, and description were fairly
                simple. We performed simple regEx to clean up the “\n” characters and other spaces
                that appeared when we output it to a text file. </p>
            <p>From here, we discovered that we could simply tell ChatGPT to generate new items and
                put them in the format we desire. However, this was too simple. We decided we could
                work on using API Keys and OpenAI to train our own chatbot to fulfill a purpose of
                making a set of generated items that are entirely fictional, but based on what
                information we feed it. From this, we began work on using the <a
                    href="https://platform.openai.com/docs/api-reference">Open AI documentation</a>
                to begin writing Python that performs this task. With some help from other sources
                giving us <a
                    href="https://discusschatgpt.com/training-your-own-chatgpt-model-a-step-by-step-tutorial/"
                    >overviews of the system</a>, we began to learn more about training an AI to
                make our idea work. </p>
            <h2>Fine-Tuning</h2>
            <p>Soon after getting our API Key working and being able to communicate with the ada
                model in GPT-Turbo 3.5, we realized we still have much work to do in making our AI
                work for us. The method for achieving this lies in utilizing fine-tuning. This
                involves creating a ruleset that our model follows so that instead of manually
                telling the model what we want to see for examples, it has background information
                that it applies so that it can do more with less in the prompt given. For fine
                tuning, we looked at the <a href="https://github.com/openai/openai-cookbook">Open AI
                    Cookbook</a> and the <a
                    href="https://platform.openai.com/docs/guides/fine-tuning">Fine-Tuning
                    documentation provided by OpenAI</a>
            </p>
            <p>From here, we found that fine-tuning is not as easy as it seems. We discovered that
                we needed to use a JSON file in order to train an ai model. This was a big part of
                the process, as we learned that we needed to implement a prompt and completion
                system. This involves giving an example of a prompt, and then an example of a
                completion. We decided the prompts should simply be asking the ai to generate a new
                item, and the completions should be each item type, name, and description from our
                source document. By using a TSV file, we were able to regex out any error-causing
                symbols in the format of our source information and send wrap the correct tags and
                prompt/completion tags around the correct information. Our JSON file is located <a
                    href="https://github.com/LizardWizard01/Dark-Souls-Lore-ChatGPT/blob/main/txtFiles/fine-tune-testing1.jsonl"
                    >here</a>, and is useful in showing what the model looks like, and how our ai
                reads through the information that we gave it.</p>
            <p>After making the JSON file, we needed to train our model with it so that it can be a
                unique kind of ai model. We formatted this to work with the base ada model by
                OpenAI, and used our command line to process this, since on our local computers, we
                were having differing issues in associating the model with the JSON file in Python.
                We followed the official <a
                    href="https://platform.openai.com/docs/guides/fine-tuning">OpenAI documentation
                    for fine-tuning</a> and intiated our model in command line, or CLI. This was
                succesful, but we still had questions on how to use it.</p>
            <h3>Implementing the Model</h3>
            <p>With our issues going on in the Python environment, we realized we had to use the CLI
                to send a prompt to the ai. We sent out a few, and the responses came back somewhat
                unfinished. Words would be cut off, and we were a little lost on what to do with it.
                The prompts and answers looked a bit like this:</p>
            <table>
                <tr>
                    <th>Prompts</th>
                    <th>Completions</th>
                </tr>
                <tr>
                    <td>"Could you generate a new item in the dark souls universe?"</td>
                    <td>Could you generate a new item in the dark souls universe? This act disturbs
                        the sanctity of the Gods, and thousands of ordinary humans</td>
                </tr>
            </table>
            <p>On top of being short and unfinished, they are still stuck in a command line. We got
                the idea that there was another way to view thiss, but mostly we wanted to implement
                it in python and switch the model. From here, we encountered another issue. We were
                finding many errors about chat completion lines and connecting to the OpenAI service
                to use our model. After some more research, we found out a big game-changer. Our
                model cannot be trained as a chat-completion model! As it turns out, it is currently
                only possible to train completion models on specific data. This explains why we got
                somewhat confusing data back, along with completion lines that were shorter and less
                cohesive and original compared to our tests with other models and Chat GPT. We then
                discovered that we were actually able to use the OpenAI Playground in order to
                alter, control, and use the fine-tuned model. You can see some examples of these
                outputs and visit the playground <a href="examples.html">here</a>. </p>
            <h4>Conclusion</h4>
            <p>That's about everything we did along the way. Everything after (and somewhat mixed in
                throughout this whole process) is the story of us building our site and preparing
                our data in a way that helps explain what we have been working on. Overall, we
                learned a lot and discovered the inner workings of ai. We feel this was a very
                adventurous project due to the growing implementation of ai models everywhere. </p>
        </div>
        <div class="doc">
            <h1>What You’ll See Later</h1>
            <br />
            <p>Eventually, we will have different parts of the page that will be viewable and will
                show the results of our tinkerings with OpenAI. We will be looking at different
                aspects of the source files, and comparing them with our eventual outputs from our
                trained model. This will allow us to study the creativity and intelligence of the
                current AI system, along with learning how to work with AI models. Overall, some
                major goals of this project are to gain a better understanding of AI models, compare
                generated results with ideas by humans, and analyze the errors made by the models. </p>
            <p>For more information, visit our GitHub repository <a
                    href="https://github.com/LizardWizard01/Dark-Souls-Lore-ChatGPT">here</a>.
                There, you can find what we're working with and see a preview of our code and
                more.</p>
        </div>
        <img src="pics/bonfire.png" alt="dark souls bonfire"/>
    </body>
</html>
